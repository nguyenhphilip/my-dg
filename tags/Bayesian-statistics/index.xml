<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bayesian statistics on</title><link>https://nguyenhphilip.github.io/my-dg/tags/Bayesian-statistics/</link><description>Recent content in Bayesian statistics on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://nguyenhphilip.github.io/my-dg/tags/Bayesian-statistics/index.xml" rel="self" type="application/rss+xml"/><item><title>selection-distortion effect</title><link>https://nguyenhphilip.github.io/my-dg/notes/statistics/selection-distortion-effect/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://nguyenhphilip.github.io/my-dg/notes/statistics/selection-distortion-effect/</guid><description>source: In Statistical Rethinking , the author presents a particularly relevant example of how negative correlations arise from selection processes:
It seems like the most newsworthy scientific studies are the least trustworthy.
There&amp;rsquo;s no real underlying reason to believe that trustworthiness correlates with newsworthyness. But this spurious correlation can arise as a result of strict selection processes, such as selecting who gets science funding:
&amp;hellip; all that is necessary for such a negative correlation to arise is that peer reviewers care about both newsworthiness and trustworthiness.</description></item></channel></rss>